{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection Challenge Notebook\n",
    "\n",
    "This notebook will:\n",
    "1. Set up the environment\n",
    "2. Prepare the dataset\n",
    "3. Train a YOLOv8 model\n",
    "4. Generate predictions in the required format\n",
    "5. Prepare submission files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install ultralytics matplotlib seaborn pandas tqdm\n",
    "!pip install --upgrade ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ultralytics import YOLO\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "BASE_DIR = Path('.')\n",
    "DATA_DIR = BASE_DIR / 'Object_detection_RMEDU'\n",
    "TRAIN_DIR = DATA_DIR / 'train'\n",
    "TEST_DIR = DATA_DIR / 'test'\n",
    "IMAGES_DIR = TRAIN_DIR / 'images'\n",
    "LABELS_DIR = TRAIN_DIR / 'labels'\n",
    "TEST_IMAGES_DIR = TEST_DIR / 'images'\n",
    "SUBMISSION_DIR = BASE_DIR / 'submission'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "SUBMISSION_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Verify paths\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Train directory: {TRAIN_DIR}\")\n",
    "print(f\"Test directory: {TEST_DIR}\")\n",
    "print(f\"Submission directory: {SUBMISSION_DIR}\")\n",
    "\n",
    "# Check if directories exist\n",
    "print(f\"\\nTrain images exist: {IMAGES_DIR.exists()}\")\n",
    "print(f\"Train labels exist: {LABELS_DIR.exists()}\")\n",
    "print(f\"Test images exist: {TEST_IMAGES_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load class names\n",
    "with open('class_names.txt', 'r') as f:\n",
    "    class_names = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "num_classes = len(class_names)\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Class names: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the dataset\n",
    "train_images = list(IMAGES_DIR.glob('*.jpg'))\n",
    "train_labels = list(LABELS_DIR.glob('*.txt'))\n",
    "test_images = list(TEST_IMAGES_DIR.glob('*.jpg'))\n",
    "\n",
    "print(f\"Number of training images: {len(train_images)}\")\n",
    "print(f\"Number of training labels: {len(train_labels)}\")\n",
    "print(f\"Number of test images: {len(test_images)}\")\n",
    "\n",
    "# Check if all images have corresponding labels\n",
    "image_names = [img.stem for img in train_images]\n",
    "label_names = [lbl.stem for lbl in train_labels]\n",
    "missing_labels = set(image_names) - set(label_names)\n",
    "missing_images = set(label_names) - set(image_names)\n",
    "\n",
    "print(f\"Images without labels: {len(missing_labels)}\")\n",
    "print(f\"Labels without images: {len(missing_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some sample images with annotations\n",
    "def plot_sample_images(num_samples=3):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Select a random image\n",
    "        img_idx = random.randint(0, len(train_images)-1)\n",
    "        img_path = train_images[img_idx]\n",
    "        label_path = LABELS_DIR / f\"{img_path.stem}.txt\"\n",
    "        \n",
    "        # Read image\n",
    "        img = plt.imread(img_path)\n",
    "        h, w, _ = img.shape\n",
    "        \n",
    "        # Read annotations\n",
    "        with open(label_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        # Plot image\n",
    "        plt.subplot(1, num_samples, i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Sample {i+1}\")\n",
    "        \n",
    "        # Plot bounding boxes\n",
    "        for line in lines:\n",
    "            class_id, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "            \n",
    "            # Convert normalized coordinates to pixel values\n",
    "            x_center *= w\n",
    "            y_center *= h\n",
    "            width *= w\n",
    "            height *= h\n",
    "            \n",
    "            # Calculate corner points\n",
    "            x1 = int(x_center - width/2)\n",
    "            y1 = int(y_center - height/2)\n",
    "            x2 = int(x_center + width/2)\n",
    "            y2 = int(y_center + height/2)\n",
    "            \n",
    "            # Draw rectangle\n",
    "            plt.gca().add_patch(plt.Rectangle(\n",
    "                (x1, y1), width, height,\n",
    "                fill=False, color='red', linewidth=2\n",
    "            ))\n",
    "            \n",
    "            # Add class name\n",
    "            plt.text(\n",
    "                x1, y1-5, class_names[int(class_id)],\n",
    "                color='red', fontsize=10, backgroundcolor='white'\n",
    "            )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_sample_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data.yaml file for YOLOv8\n",
    "data_yaml = f\"\"\"\n",
    "path: {DATA_DIR.absolute()}\n",
    "train: train/images\n",
    "val: train/images  # Using training data as validation since no separate validation set\n",
    "test: test/images\n",
    "\n",
    "nc: {num_classes}\n",
    "names: {class_names}\n",
    "\"\"\"\n",
    "\n",
    "with open('data.yaml', 'w') as f:\n",
    "    f.write(data_yaml)\n",
    "\n",
    "print(\"Created data.yaml file:\")\n",
    "print(data_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')  # Using pretrained nano model for faster training\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data='data.yaml',\n",
    "    epochs=50,  # Adjust based on time constraints\n",
    "    imgsz=640,\n",
    "    batch=16,   # Adjust based on GPU memory\n",
    "    name='object_detection_model',\n",
    "    project='runs/train',\n",
    "    exist_ok=True,\n",
    "    verbose=True,\n",
    "    device=0,   # Use GPU\n",
    "    patience=5, # Early stopping\n",
    "    save_period=5  # Save every 5 epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training results\n",
    "def plot_training_results():\n",
    "    # Find the latest training run\n",
    "    train_dir = Path('runs/train')\n",
    "    latest_run = max([d for d in train_dir.glob('object_detection_model*') if d.is_dir()], key=os.path.getmtime)\n",
    "    results_file = latest_run / 'results.csv'\n",
    "    \n",
    "    if not results_file.exists():\n",
    "        print(\"No results.csv found. Training might not have completed.\")\n",
    "        return\n",
    "    \n",
    "    # Read results\n",
    "    results = pd.read_csv(results_file)\n",
    "    \n",
    "    # Plot metrics\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot training and validation loss\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(results['epoch'], results['train/box_loss'], label='train/box_loss')\n",
    "    plt.plot(results['epoch'], results['val/box_loss'], label='val/box_loss')\n",
    "    plt.title('Box Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(results['epoch'], results['train/cls_loss'], label='train/cls_loss')\n",
    "    plt.plot(results['epoch'], results['val/cls_loss'], label='val/cls_loss')\n",
    "    plt.title('Class Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot mAP metrics\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(results['epoch'], results['metrics/mAP50(B)'], label='mAP@50')\n",
    "    plt.plot(results['epoch'], results['metrics/mAP50-95(B)'], label='mAP@50-95')\n",
    "    plt.title('mAP Metrics')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('mAP')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot precision and recall\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(results['epoch'], results['metrics/precision(B)'], label='precision')\n",
    "    plt.plot(results['epoch'], results['metrics/recall(B)'], label='recall')\n",
    "    plt.title('Precision and Recall')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "best_model_path = 'runs/train/object_detection_model/weights/best.pt'\n",
    "model = YOLO(best_model_path)\n",
    "\n",
    "# Make predictions on test set\n",
    "print(\"Generating predictions on test set...\")\n",
    "test_images_paths = [str(p) for p in TEST_IMAGES_DIR.glob('*.jpg')]\n",
    "\n",
    "# Clear submission directory\n",
    "for f in SUBMISSION_DIR.glob('*.txt'):\n",
    "    f.unlink()\n",
    "\n",
    "# Predict on each test image\n",
    "for img_path in tqdm(test_images_paths):\n",
    "    # Get image filename without extension\n",
    "    img_name = Path(img_path).stem\n",
    "    \n",
    "    # Make prediction\n",
    "    results = model.predict(img_path, conf=0.25, iou=0.45, verbose=False)\n",
    "    \n",
    "    # Create output file\n",
    "    output_file = SUBMISSION_DIR / f\"{img_name}.txt\"\n",
    "    \n",
    "    # Write predictions to file\n",
    "    with open(output_file, 'w') as f:\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            if boxes is not None:\n",
    "                for box in boxes:\n",
    "                    # Get class ID and normalized coordinates\n",
    "                    cls = int(box.cls)\n",
    "                    x_center, y_center, width, height = box.xywhn[0].tolist()\n",
    "                    \n",
    "                    # Write in required format: <class_id> <x_center> <y_center> <width> <height>\n",
    "                    f.write(f\"{cls} {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "print(f\"Generated {len(list(SUBMISSION_DIR.glob('*.txt')))} prediction files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify submission format\n",
    "sample_files = list(SUBMISSION_DIR.glob('*.txt'))[:5]\n",
    "for file in sample_files:\n",
    "    print(f\"File: {file.name}\")\n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines[:3]:  # Show first 3 lines\n",
    "            print(line.strip())\n",
    "        if len(lines) > 3:\n",
    "            print(f\"... and {len(lines)-3} more lines\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission archive\n",
    "submission_archive = 'submission.zip'\n",
    "shutil.make_archive(submission_archive.replace('.zip', ''), 'zip', SUBMISSION_DIR)\n",
    "\n",
    "print(f\"Submission archive created: {submission_archive}\")\n",
    "print(f\"Archive size: {os.path.getsize(submission_archive) / (1024*1024):.2f} MB\")\n",
    "\n",
    "# Verify archive contents\n",
    "with zipfile.ZipFile(submission_archive, 'r') as zip_ref:\n",
    "    file_list = zip_ref.namelist()\n",
    "    print(f\"Number of files in archive: {len(file_list)}\")\n",
    "    print(\"Sample files:\")\n",
    "    for f in file_list[:5]:\n",
    "        print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Visualize predictions on test images\n",
    "def visualize_predictions(num_samples=3):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Get random test images\n",
    "    sample_files = random.sample(test_images_paths, num_samples)\n",
    "    \n",
    "    for i, img_path in enumerate(sample_files):\n",
    "        img_name = Path(img_path).stem\n",
    "        \n",
    "        # Load image\n",
    "        img = plt.imread(img_path)\n",
    "        h, w, _ = img.shape\n",
    "        \n",
    "        # Load predictions\n",
    "        pred_file = SUBMISSION_DIR / f\"{img_name}.txt\"\n",
    "        \n",
    "        # Plot image\n",
    "        plt.subplot(1, num_samples, i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Prediction: {img_name}\")\n",
    "        \n",
    "        if pred_file.exists():\n",
    "            with open(pred_file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            for line in lines:\n",
    "                class_id, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "                \n",
    "                # Convert normalized coordinates to pixel values\n",
    "                x_center *= w\n",
    "                y_center *= h\n",
    "                width *= w\n",
    "                height *= h\n",
    "                \n",
    "                # Calculate corner points\n",
    "                x1 = int(x_center - width/2)\n",
    "                y1 = int(y_center - height/2)\n",
    "                x2 = int(x_center + width/2)\n",
    "                y2 = int(y_center + height/2)\n",
    "                \n",
    "                # Draw rectangle\n",
    "                plt.gca().add_patch(plt.Rectangle(\n",
    "                    (x1, y1), width, height,\n",
    "                    fill=False, color='lime', linewidth=2\n",
    "                ))\n",
    "                \n",
    "                # Add class name\n",
    "                plt.text(\n",
    "                    x1, y1-5, class_names[int(class_id)],\n",
    "                    color='lime', fontsize=10, backgroundcolor='black'\n",
    "                )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has:\n",
    "1. Set up the environment and installed necessary packages\n",
    "2. Explored and visualized the dataset\n",
    "3. Created a data.yaml configuration file for YOLOv8\n",
    "4. Trained a YOLOv8 model on the training data\n",
    "5. Generated predictions on the test set in the required format\n",
    "6. Created a submission archive with all prediction files\n",
    "\n",
    "The submission files are in the `submission` directory and packaged as `submission.zip`.\n",
    "\n",
    "To submit to the competition:\n",
    "1. Download the `submission.zip` file\n",
    "2. Extract it to get all the prediction files\n",
    "3. Upload the individual .txt files to the competition platform\n",
    "\n",
    "Each .txt file corresponds to a test image and contains the predicted bounding boxes in the format:\n",
    "`<class_id> <x_center> <y_center> <width> <height>`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
